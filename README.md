### Big data : 
	Big data refers to large data sets that are challenging to store,search,share,visualize and analyze.
  In distributed environmet, if the size of the file is more then  we split the file into chunks and store in multipule machines.

Hadoop solves how to store the big data, process it.So that it takes less time to complete.

### Bigdata-attributes :
	volume  	    : size of the data
 	Variety(Formats)    : Relational data, Text data, xml, Graph data(Social Network), 
	Velocity 	    : Data is generated fast and handled fast.

### Best Thing about Hadoop :
	Bring code to data rather data to code.
	Reliable : Because same data would replicated in multiple places  

### Hadoop components : 
	Hadoop distrubuted file system 
	Map Reduce

Hadoop Cluster : It is a special type of computational cluster designed for storing and analyzing the huge amounts of unstructered data in a distributed computational environament
HDFS 	       : HDFS is a file system designed for storing very large files with streaming data access pattern, running on clusters of commidity hardware. 

### HDFS Features  :
	Block file system 
	Block size is 64MB or 128 MB. It reduces the disk read time because we directly read the entire 64MB at a time. Normal file system block size is 1KB.
	Hardware failures
	Streaming data access
	
